# AI 데이터

이 문서에서는 AI 모델 학습에 사용된 데이터셋에 대해 설명합니다.

[처음으로](../overview.md) |
[소개로](00_introduction.md) |
[이전: AI 모델](01_ai_model.md) |
[다음: 모델 평가](03_ai_evaluation.md)

# 소개
백내장을 인식 할 수 있는 데이터셋을 구축 하기 위해 동공 탐지 후 객체를 크롭하였습니다
# 구축 목적
모바일에서 백내장을 진단 하는 서비스를 위해 백내장 안구 사진 9257장, 일반 안구 사진 8272 장 수집하여 분류

# 데이터 변경 이력
데이터 변경이 생길 때마다 버전 추가

|버전| 일자| 변경내용| 비고|
|--|--|--|--|
|1.0| 2025-01-07| 데이터 1차 수집 완료||
|1.1| 2025-02-05| 데이터 전처리 완료||
|1.2| 2024-02-18| 데이터 추가 수집 완료||

# 메타데이터 구조표
| | | | |
|--|--|--|--|
|**데이터 영역**| 영상 이미지|**데이터 형식**| 이미지|
|**데이터 형식**| jpg, png|**데이터 출처**| 하단 참조|
|**라벨링 유형**| Classification|**라벨링 형식**| 파일명|
|**데이터 활용 서비스**| 백내장 검출| **데이터 구축 연도/데이터 구축량**| 2024년 / 이미지 17,529|

# 데이터 출처 및 라이센스

|제공자| 플랫폼| 링크| 라이센스|
|--|--|--|--|
|alexandramohammed|Kaggle| [Link](https://www.kaggle.com/datasets/alexandramohammed/cataract-image)| Unknown|
|hemooredaoo|Kaggle| [Link](https://www.kaggle.com/datasets/hemooredaoo/cataract)| Unknown|
|mohammedgamal37l30| Kaggle| [Link](https://www.kaggle.com/datasets/mohammedgamal37l30/eye-cataractmature-immature-normal)| Unknown|
|krishnabojha| Github| [Link](https://github.com/krishnabojha/Cataract_Detection-using-CNN/tree/master/Dataset)| Unknown|
|piygot5| Github| [Link](https://github.com/piygot5/Cataract-Detection-and-Classification/tree/master/phase%201%20Binary/Binary%20classification/dataset/phase1)| Unknown|
|akshayramakrishnan28| Kaggle| [Link](https://www.kaggle.com/datasets/akshayramakrishnan28/cataract-classification-dataset)| CC BY-SA 4.0|
|kershrita| Kaggle| [Link](https://www.kaggle.com/datasets/kershrita/cataract)| MIT|

# 데이터 전처리
## 1.Iris localization
### 개요
본 프로젝트에서는 입력 이미지에서 홍채(iris)의 위치가 거의 동일할 것이라는 가정하에, 학습과 평가에 사용될 데이터에 대해 이미지 정합(image registration)을 수행합니다. 이는 모델이 보다 일관된 특징을 학습할 수 있도록 하기 위함이며, 특히 눈 위치가 제각각인 원본 이미지(AS-IS)를 동일한 기준으로 정렬된 이미지(TO-BE)로 변환하는 것이 목표입니다.

이를 위해 SimpleITK 패키지를 활용하여 이미지 정합을 수행하였으며, 이를 통해 홍채의 위치를 맞추는 과정과 그 한계를 분석하였습니다.
### 이미지 정합의 필요성

#### 기존 데이터의 문제점
홍채 기반 모델을 학습할 때, 기존 데이터셋은 개인의 눈 위치가 제각각으로 존재하는 경우가 많았습니다.
이로 인해 모델이 학습할 때 홍채 자체의 특징보다는 불필요한 위치 변화에 의해 발생하는 패턴을 학습할 가능성이 있습니다. 특히 CNN 기반의 딥러닝 모델은 위치 불변성이 어느 정도 보장되지만, 작은 위치 차이가 지속적으로 발생하면 모델이 일반화하기 어려워질 수 있습니다.

#### 목표
모든 이미지에서 홍채의 위치를 정렬하여 모델이 불필요한 위치 변화에 의한 변수를 학습하지 않도록 하는 것이 핵심 목표입니다.
이를 통해 모델이 홍채의 형태, 색상, 질감 등의 핵심적인 생체 정보를 더 잘 학습할 수 있도록 유도합니다.

### 방법
이미지 정합(Image Registration)은 서로 다른 이미지들을 동일한 기준으로 정렬하는 기술로, 본 프로젝트에서는 SimpleITK 패키지를 활용하여 수행하였습니다.
#### 적용방식
1. 기준 이미지(Reference Image) 선택
    - 기준이 되는 홍채 위치를 정한 후, 모든 이미지를 이에 맞춰 정렬한다.
2. Transform을 적용하여 이미지 정렬
    - SimpleITK의 정합 기법을 활용하여 입력 이미지를 기준 이미지에 맞춰 변형(translation, scaling, rotation 등)한다.
3. 정합된 이미지로 데이터셋 변환
    - 모든 이미지에 동일한 변환을 적용하여 일관된 데이터셋을 생성한다.

## 2.Salt and pepper noise 제거
### 개요
본 프로젝트에서는 입력 이미지에서 발생하는 Salt-and-Pepper Noise를 제거하여 더 깨끗한 데이터셋을 구축하는 것을 목표로 합니다.

Salt-and-Pepper Noise는 임의의 픽셀이 흰색(255) 또는 검은색(0)으로 변하는 형태의 잡음으로, 센서 오류, 전송 중 신호 손실 등의 이유로 발생할 수 있습니다. 이러한 노이즈가 포함된 이미지는 모델 학습 시 불필요한 변동성을 증가시키며, 특징 추출에도 부정적인 영향을 미칠 수 있습니다. 따라서, 효과적인 노이즈 제거 기법을 적용하여 보다 안정적인 데이터셋을 구축하는 것이 중요합니다.

### 노이즈 제거의 필요성
#### 기존 데이터의 문제점
Salt-and-Pepper Noise가 포함된 이미지는 픽셀 단위로 랜덤한 흑백 점들이 분포하여, 이미지의 원본 정보를 손실시킵니다. 	특히, 딥러닝 모델이 이러한 노이즈를 실제 특징으로 잘못 학습할 가능성이 있으며, 결과적으로 모델의 성능 저하를 초래할 수 있습니다. 노이즈가 많은 데이터는 경계 검출 및 특징 추출 과정에서 잘못된 정보를 포함할 가능성이 높아, 정제되지 않은 데이터로 인해 모델이 불필요한 패턴을 학습할 수도 있습니다.
#### 목표
Salt-and-Pepper Noise를 효과적으로 제거하여 더 깨끗한 이미지 데이터셋을 구축하는것이 핵심 목표입니다. 노이즈 제거는 학습 및 평가 데이터셋에만 적용하며, 실제 추론(Inference) 단계에서는 적용하지 않습니다. 이를 통해, 모델이 보다 신뢰할 수 있는 특징을 학습하고, 노이즈로 인해 발생할 수 있는 불필요한 일반화 오류를 방지합니다.

### 방법
Salt-and-Pepper Noise 제거를 위해 대표적인 필터링 기법을 적용하였습니다.
#### 적용방식
1. 미디언 필터(Median Filter) 적용
    - 미디언 필터는 중앙값 기반 필터링 기법으로, Salt-and-Pepper Noise 제거에 효과적입니다.
2. 양방향 필터(Bilateral Filter) 적용
    - 미디언 필터만으로 제거가 어려운 경우, 추가적으로 양방향 필터(Bilateral Filter)를 적용하여 엣지를 보존하면서 노이즈를 제거합니다.

## 3.중복 제거
### 개요
본 프로젝트에서는 중복된 이미지 데이터를 제거하여 학습 데이터의 품질을 향상시키는 것을 목표로 합니다
데이터셋 구축 과정에서 동일한 이미지가 여러 번 포함되거나, 유사도가 매우 높은 이미지가 중복될 가능성이 존재합니다. 이러한 중복 데이터는 모델이 불필요하게 같은 데이터를 학습하는 결과를 초래하며, 일반화 성능을 저하시킬 수 있습니다. 따라서, 효과적인 중복 제거 기법을 적용하여 보다 효율적이고 균형 잡힌 데이터셋을 구축하는 것이 중요합니다.
### 중복 제거의 필요성
#### 기존 데이터의 문제점
동일한 이미지가 여러 번 포함될 경우, 모델이 특정 샘플을 과대 학습할 가능성이 높아집니다. 학습 과정에서 동일한 데이터가 반복적으로 사용되면, 다양한 데이터 학습이 제한되며, 모델이 새로운 데이터에 대한 일반화 능력을 갖추기 어려워집니다. 데이터셋 내 불균형이 발생할 수 있으며, 특정 클래스에 중복 샘플이 많아질 경우 모델이 편향된 학습을 하게 될 위험이 있습니다.
#### 목표
데이터셋에서 동일한 이미지 또는 유사도가 높은 이미지를 효과적으로 탐지하고 제거하여, 균형 잡힌 학습 데이터셋을 구축합니다.
중복 제거는 학습 및 평가 데이터셋에만 적용하며, 실제 추론(Inference) 단계에서는 별도의 처리가 필요하지 않습니다. 이를 통해, 모델이 보다 다양한 데이터를 학습할 수 있도록 하고, 일반화 성능을 향상시키는 것이 최종 목표입니다.
### 방법
중복된 데이터를 탐지하고 제거하기 위해 다양한 유사도 측정 기법을 적용하였습니다.
1. 해밍 거리 기반 해시 기법 적용
    - Perceptual Hashing(PHash) 또는 Difference Hash(DHash) 기법을 활용하여 각 이미지의 해시 값을 생성합니다. 두 이미지의 해시 값 간의 해밍 거리(Hamming Distance)를 계산하여, 일정 기준 이하의 차이를 보이는 이미지를 중복으로 간주하고 제거합니다.
2. 구조적 유사도(SSIM, Structural Similarity Index) 기반 비교
    - SSIM은 이미지의 밝기, 대비, 구조 정보를 고려하여 유사도를 측정하는 방식으로, 픽셀 단위 차이가 아닌 시각적 유사성을 평가하는 데 유용합니다
