# AI 모델

이 문서에서는 프로젝트에서 활용된 모델에 대해 설명합니다.

[처음으로](../overview.md) |
[소개로](00_introduction.md) |
[이전: 소개](00_introduction.md) |
[다음: 데이터](02_ai_data.md)

# 모델 개요
## 설계 의도 및 목적
현대 의료 환경에서는 백내장(Cataract)과 같은 안과 질환을 조기에 발견하는 것이 매우 중요합니다. 그러나 전문적인 의료 장비가 필요하거나 안과 전문의를 직접 방문하기 어려운 경우, 이러한 진단이 지연될 가능성이 큽니다. 이에 본 프로젝트에서는 온디바이스(온디바이스 AI) 기반의 Eye Detection 및 Cataract Classifier 모델을 개발하여, 모바일 및 임베디드 디바이스에서 실시간으로 눈을 감지하고 백내장 여부를 판단할 수 있도록 하였습니다.


1. 모바일 환경에서의 실시간 동작
    - 네트워크 연결 없이도 즉시 실행할 수 있도록 온디바이스 AI 모델을 구현하여, 의료 접근성이 낮은 환경에서도 활용할 수 있도록 하였습니다.
2. 경량화된 모델 설계
    - 모바일 및 임베디드 디바이스에서 원활하게 실행될 수 있도록 MobileNet 기반의 경량화된 모델을 채택하고, ONNX 변환을 통해 최적화하였습니다.
3. 정확한 Eye Detection 및 Cataract 분류
    - Eye Detection 모델을 통해 사용자의 눈을 정확하게 감지하고, Cataract Classifier를 활용하여 백내장 여부를 분석할 수 있도록 모델을 분리하여 성능을 최적화하였습니다.
4. 신뢰할 수 있는 의료 보조 솔루션 제공
    - 백내장 조기 진단을 위한 보조 도구로 활용될 수 있도록 높은 정확도와 신뢰도를 확보하는 것을 목표로 하였습니다.

## 온디바이스 모델을 선택한 이유
본 프로젝트에서는 백내장(Cataract) 분류 및 눈 감지 기능을 수행하는 AI 모델을 개발하면서, 클라우드 기반이 아닌 온디바이스(On-Device) AI 방식으로 동작하도록 설계하였습니다. 이를 선택한 주요 이유는 다음과 같습니다.

1. 네트워크 연결 없이도 사용 가능
    - 의료 접근성이 낮은 환경(예: 인터넷 연결이 어려운 지역)에서도 사용할 수 있도록, 네트워크 없이 독립적으로 실행할 수 있는 온디바이스 AI 모델을 채택하였습니다.
    - 응급 상황이나 이동 중에도 즉시 분석이 가능하도록 하여, 사용자의 편의성을 높였습니다.
2. 빠른 응답 속도
    - 클라우드 서버를 활용하는 경우, 데이터를 업로드하고 분석한 후 다시 결과를 받아오는 과정에서 지연(latency)이 발생할 수 있습니다.
    - 온디바이스 모델은 디바이스 내에서 직접 연산을 수행하기 때문에 실시간으로 빠르게 결과를 확인할 수 있습니다.
3. 사용자 개인정보 보호 강화
    - 안구 이미지는 민감한 생체 정보에 해당하므로, 데이터를 서버로 전송하지 않고 디바이스 내에서 처리함으로써 개인정보 보호를 강화할 수 있습니다.
    - 클라우드 기반 분석 방식에서는 데이터 유출이나 해킹 위험이 존재할 수 있지만, 온디바이스 AI는 이러한 보안 리스크를 줄이는 데 유리합니다.
4. 비용 절감
    - 클라우드 기반 AI 모델을 사용할 경우, 서버 운영 및 유지보수 비용이 발생합니다. 특히, 많은 사용자가 서비스를 이용하면 서버 비용이 증가할 수 있습니다.
    - 온디바이스 AI는 클라우드 비용 없이 로컬에서 실행되므로, 장기적인 비용 절감 효과를 기대할 수 있습니다.
5. 실시간 의료 보조 솔루션으로 활용 가능
    - 백내장과 같은 안과 질환은 조기 발견이 중요하기 때문에, 사용자가 즉시 결과를 확인하고 필요할 경우 빠르게 병원을 방문할 수 있도록 실시간 분석이 필요합니다.
    - 온디바이스 모델을 활용하면 빠른 분석을 통해 의료진의 진단을 보조하는 역할을 수행할 수 있습니다.

## ONNX 모델로 변환한 이유
본 프로젝트에서 개발한 Eye Detection 및 Cataract Classifier 모델은 최적의 성능과 호환성을 확보하기 위해 ONNX(Open Neural Network Exchange) 형식으로 변환하였습니다. ONNX 모델을 채택한 주요 이유는 다음과 같습니다.

1. 다양한 플랫폼 및 프레임워크와의 호환성
    - ONNX는 TensorFlow, PyTorch, Keras 등 다양한 딥러닝 프레임워크에서 학습된 모델을 변환하여 사용할 수 있도록 지원합니다.
    - 이를 통해 특정 프레임워크에 종속되지 않고, 다양한 환경(모바일, 클라우드, 임베디드 디바이스 등)에서 활용할 수 있습니다.
2. 온디바이스 실행 최적화
    - ONNX는 다양한 하드웨어(예: CPU, GPU, NPU, DSP)에서 실행될 수 있도록 설계되어 있어, 모바일 및 임베디드 디바이스에서 원활하게 동작할 수 있습니다.
    - ONNX Runtime을 활용하면 최적화된 연산(Graph Optimization) 을 적용하여 모델의 추론 속도를 향상시킬 수 있습니다.
3. 추론 속도 향상 및 경량화
    - ONNX는 연산 그래프 최적화(Operator Fusion, Constant Folding 등)를 통해 실행 속도를 높이고, 메모리 사용량을 줄이는 기능을 제공합니다.
    - 이를 통해 모바일 및 임베디드 디바이스에서 실시간 추론 성능을 개선할 수 있습니다.
    - 기존 TensorFlow 또는 PyTorch 모델보다 가벼운 ONNX 형식으로 변환하면, 추론 과정에서의 메모리 사용량이 감소하여 저사양 기기에서도 원활하게 동작할 수 있습니다.

4. 하드웨어 가속기 활용 가능
    - ONNX Runtime은 다양한 하드웨어 가속기를 지원합니다.
    - 예를 들어, Qualcomm의 SNPE, NVIDIA TensorRT, Intel OpenVINO 등의 가속 엔진과 연동하여 성능을 극대화할 수 있습니다.
    - 이를 통해 온디바이스 환경에서도 GPU, NPU 등의 가속기를 활용하여 보다 빠른 추론 속도를 제공할 수 있습니다.

5. 운영 및 유지보수 효율성 증가
    - ONNX를 사용하면 여러 AI 프레임워크 간 모델을 쉽게 변환할 수 있어, 새로운 환경에 배포하거나 모델을 업데이트할 때 발생하는 부담을 줄일 수 있습니다.
    - 또한, ONNX 형식으로 변환한 모델을 다양한 AI 엔진에서 공통적으로 사용할 수 있어 개발 및 유지보수가 용이합니다.


# 모델 아키텍처
## 전체 아키텍처 개요
본 프로젝트에서는 눈 확인(Eye Verification) 모델과 백내장 분류(Cataract Classifier) 모델을 분리하여 설계하였으며, 온디바이스 환경에서 실시간으로 동작할 수 있도록 최적화하였습니다. 특히, Eye Verification 모델은 MobileNet을 활용하여 입력 이미지의 임베딩을 추출한 후, 미리 저장된 임베딩과의 유사도를 비교하여 해당 영역이 실제 눈인지 판별하는 방식을 적용하였습니다.
전체적인 아키텍처는 다음과 같은 단계로 구성됩니다.
1. 입력(Input) – 카메라 영상 또는 이미지
    - 사용자는 스마트폰, 태블릿, 혹은 임베디드 디바이스의 카메라를 활용하여 눈을 촬영합니다.
    - 입력 데이터는 일반적으로 RGB 이미지 형식(224×224 크기) 으로 전처리됩니다.
    - 실시간 분석을 위해 프레임 단위로 처리할 수도 있습니다.
2. Eye Verification (눈 확인) 모델 – 임베딩 기반 유사도 분석
    - 입력된 이미지에서 해당 영역이 실제 눈인지 확인하는 과정을 수행합니다.
    - MobileNet을 활용하여 입력 이미지의 임베딩 정보를 추출한 후, 미리 저장된 참조(Reference) 임베딩과 유사도 계산을 수행하여 해당 영역이 눈인지 판별합니다.
3. Cataract Classifier (백내장 분류) 모델
    - Eye Verification 모델을 통과한 눈 영역을 입력으로 받아, 백내장 여부를 분류합니다.
    - MobileNet 기반의 분류(Classification) 모델을 사용하여, 백내장의 유무를 판단하고 결과를 출력합니다.
4. 결과 출력 및 사용자 피드백
    - Cataract Classifier의 결과를 사용자에게 제공하며, 시각적인 피드백(UI)과 함께 출력됩니다.
    - 백내장 가능성이 높은 경우, 의료 기관 방문을 권장하는 추가 메시지를 제공할 수 있습니다.
    - 결과를 저장하거나 의료진과 공유할 수 있도록 기능을 확장할 수도 있습니다.

## MobileNet 모델 아키텍처 및 장점
### MobileNet 구조 요약
1. Conv 3×3 + BatchNorm + ReLU
2. Depthwise Separable Convolution 블록 (× 여러 개)
3. Global Average Pooling (GAP)
4. Fully Connected Layer (Eye Verification model 에서는 제거후 embedding 만 사용)

### Eye Verification 모델 구조
이 모델은 MobileNet을 활용하여 임베딩을 추출하고, 미리 저장된 참조(Reference) 임베딩과 유사도를 비교하여 눈 여부를 판별하는 방식으로 동작합니다.
Eye Verification 모델은 크게 네 가지 단계로 구성됩니다.

1. 입력 이미지 전처리
    - 입력 이미지를 MobileNet의 입력 형식(예: 224×224 크기의 RGB 이미지)으로 변환
    - 정규화 및 데이터 증강 적용 가능
2. 임베딩(Embedding) 추출
    - MobileNet을 활용하여 이미지의 특징 벡터(임베딩) 생성
3. 유사도 계산(Similarity Matching)
    - 미리 저장된 참조 임베딩과 비교하여 해당 영역이 눈인지 판별
4. 출력 (눈 여부 판별 결과 반환)
    - 유사도 점수가 임계값(threshold) 이상이면 “눈”으로 판단, 아니면 제외

### Cataract Classifier 모델 구조
Cataract Classifier 모델은 백내장 분류 모델로, 눈 확인(Eye Verification) 모델을 통해 확인된 눈 이미지를 받아 백내장 여부를 판별합니다. 이 모델은 MobileNet을 기반으로 한 이진 분류 모델로 설계되었으며, 정상적인 눈과 백내장이 있는 눈을 구별하는 역할을 합니다.

1. 입력 이미지
    - Eye Verification 모델을 통해 검증된 눈 이미지를 입력으로 받습니다.
    - 이 이미지는 224×224 크기로 리사이즈되어 정규화됩니다.
2. 특징 추출 (Feature Extraction)
    - MobileNet을 사용하여 입력 이미지에서 **고수준 특징(feature map)**을 추출합니다.
    - Depthwise Separable Convolution을 사용하여 연산량을 줄이고, 경량화된 모델로 성능을 최적화합니다.
3. 분류 (Classification)
    - 추출된 특징을 Fully Connected Layer (FC Layer)에 전달하여 이진 분류를 수행합니다.
    - 결과는 “정상(Normal)” 또는 “백내장(Cataract)”으로 출력됩니다.
4. 출력 (Output)
    - Softmax 또는 Sigmoid 활성화 함수를 사용하여 최종적으로 백내장 여부를 예측합니다.
    - 예측 결과는 확률 값으로 제공되며, 임계값(threshold)을 기준으로 두 클래스 중 하나로 분류됩니다.

# Eye Verification 모델 상세 설명
## 동작 원리
1. 입력 이미지
    - 입력: 눈만 크롭된 이미지가 모델의 입력으로 들어갑니다.
    - 전처리: 입력 이미지는 모델이 처리할 수 있도록 크기 조정 및 정규화됩니다.
2. 특징 추출 (Embedding 생성)
    - 목표: 입력된 눈 이미지를 기반으로 특징 벡터(임베딩)를 생성하는 과정입니다.
    - 모델은 MobileNet과 같은 경량화된 CNN을 사용하여 눈 이미지의 고유한 특징을 추출합니다.
    - 이 특징은 눈의 형태, 색상, 크기 등을 포함하는 임베딩 벡터로 변환됩니다.
3. 유사도 계산
    - 목표: 생성된 임베딩 벡터를 기존 저장된 임베딩 벡터와 비교하여, 해당 이미지가 사람의 눈인지 아닌지 판단하는 단계입니다.
    - 유클리드 거리(Euclidean distance) 또는 코사인 유사도(Cosine similarity) 같은 방식으로 벡터 간의 유사도를 계산합니다.
    - 유사도가 일정 기준 이상이면 “사람의 눈”, 그렇지 않으면 “사람의 눈이 아님”으로 판단합니다.
4. 출력 결과
    - 모델은 눈이 사람의 것인지 아닌지를 판단하여 결과를 출력합니다:
    - 사람의 눈: 입력된 눈 이미지가 사람의 눈으로 인식됩니다.
    - 사람의 눈이 아님: 입력된 눈 이미지가 사람의 눈이 아니라고 판단됩니다.

# 훈련 과정 및 주요 설정
```
DEVICE: cuda
RANDOM_SEED: 321

MODEL:
  NAME          : 'ViT_Large'
  NUM_CLASSES   : 2
  PRETRAINED    : True

  NUM_WORKERS   : 16
  N_FOLDS       : 1

TRAIN:
  BATCH_SIZE    : 128
  EPOCHS        : 100
  PATIENCE      : 5
  AMP           : True

LOSS:
  NAME: CrossEntropyLoss

OPTIMIZER:
  NAME: AdamW
  lr: 0.001
  weight_decay: 0.0001

SCHEDULER:
  scheduler_name: 'ReduceLROnPlateau'
  mode: 'max'
  factor: 0.1
  patience: 5
  min_lr: 0.000001
```
